{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   -0.007646\n",
       "years_of_experience    0.205417\n",
       "lesson_price           0.721179\n",
       "qualification          0.755963\n",
       "physics                0.187726\n",
       "chemistry              0.017825\n",
       "biology                0.023022\n",
       "english                0.013174\n",
       "geography              0.014401\n",
       "history               -0.000113\n",
       "mean_exam_points       1.000000\n",
       "Name: mean_exam_points, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv', index_col = 'Id')\n",
    "data_0 = data.copy()\n",
    "data.corr()['mean_exam_points']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(x):\n",
    "    res = x.copy()\n",
    "    for i in range(x.shape[1]):\n",
    "        res.iloc[:,i]= (res.iloc[:,i] - res.iloc[:,i].min()) / (res.iloc[:,i].max() - res.iloc[:,i].min())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "years_of_experience    0.205417\n",
       "lesson_price           0.721179\n",
       "les                    0.190075\n",
       "qualification          0.755963\n",
       "mean_exam_points       1.000000\n",
       "Name: mean_exam_points, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lessons = ['history','english', 'physics','chemistry','geography','biology']\n",
    "data.iloc[:,:-1] = min_max(data.iloc[:,:-1])\n",
    "data.insert(3,'les',(sum([data[i]*data.corr()['mean_exam_points'][i] for i in lessons])))\n",
    "data.drop(columns =['age', *lessons], inplace = True)\n",
    "data.corr()['mean_exam_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data.iloc[:,:-1].to_numpy()\n",
    "data_y = data.iloc[:,-1].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И класс терминального узла (листа)\n",
    "\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels  # y_true\n",
    "        self.prediction = self.predict()  # y_pred\n",
    "        \n",
    "    def predict(self):\n",
    "        prediction = np.mean(self.labels)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterian(labels):\n",
    "    mse =  np.std(labels)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(left_labels, right_labels, current_criterian):\n",
    "\n",
    "    # доля выборки, ушедшей в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0]) # для правого (1-p)\n",
    "    \n",
    "    return current_criterian - p * criterian(left_labels) - (1 - p) *criterian(right_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение датасета в узле\n",
    "\n",
    "def split(data, labels, index, t):\n",
    "    \n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "\n",
    "def find_best_split(data, labels, depth):\n",
    "    \n",
    "    np.random.seed(3664452660)\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    \n",
    "    min_leaf =15\n",
    "\n",
    "    current_criterian = criterian(labels)\n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    n_f = np.arange(n_features)\n",
    "#     n_features_r=np.random.choice(n_f,size=9,replace=False)\n",
    "\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        t_values =list(set([row[index] for row in data]))\n",
    "        t_values_r= np.random.choice(t_values,size=int(len(t_values)*0.1), replace=False)\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее min_leaf объектов\n",
    "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_quality = quality(true_labels, false_labels, current_criterian)\n",
    "#             print(current_quality)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "#                 print(best_quality)\n",
    "\n",
    "    return best_quality, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "def build_tree(data, labels, depth=1, depth_max = 6,  d=0):\n",
    "\n",
    "    quality, t, index = find_best_split(data, labels, depth)\n",
    "#     print(quality)\n",
    "\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда прирост качества меньше d или дерево достигло максимальной глубины\n",
    "    #  или количество потенциальных листьев достигло максимума(что при данном алгоритме идентично глубине) или все элементы одного класса\n",
    "    if quality <= d or depth>=depth_max :\n",
    "#         print(d,quality, depth, leaves)\n",
    "        \n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "    depth +=1\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree(true_data, true_labels, depth, depth_max, d)\n",
    "    false_branch = build_tree(false_data, false_labels, depth, depth_max, d)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проход объекта по дереву для его классификации\n",
    "\n",
    "def classify_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "        return classify_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание деревом для всего датасета\n",
    "\n",
    "def predict(data, tree):\n",
    "    \n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree)\n",
    "        classes.append(prediction)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(y, z):\n",
    "    return (y - z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_fit(n_trees, X_train,X_test, y_train, y_test, eta):\n",
    "    \n",
    "# Деревья будем записывать в список\n",
    "\n",
    "    trees = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        \n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "   \n",
    "        if len(trees) == 0:\n",
    "            tree = build_tree(X_train,y_train, depth_max=10, d=0.1)\n",
    "            trees.append(tree)\n",
    "            targets_train = np.array(predict(X_train, tree))\n",
    "            targets_test=np.array(predict(X_test, tree))\n",
    "#             print(r2_score(y_train, targets_train))\n",
    "#             print(r2_(y_test, targets_test))\n",
    "            \n",
    "        else:\n",
    "            tree=build_tree(X_train, (eta/(1+i*0.0001))*bias(y_train,targets_train),depth_max=6, d=0.001)           \n",
    "            trees.append(tree)\n",
    "            targets_train += np.array(predict(X_train, tree))\n",
    "            targets_test+=np.array(predict(X_test, tree))\n",
    "#             print(r2_score(y_train, targets_train))\n",
    "#             print(r2_(y_test, targets_test))\n",
    "\n",
    "    return trees, targets_train,  targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_(y,X):\n",
    "    r2_score = 1 - ((np.array(X)-np.array(y))**2).sum()/((np.array(y)-np.mean(y))**2).sum()\n",
    "    return r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data_X, \n",
    "                                                                    data_y, \n",
    "                                                                    test_size = 0.3,random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число деревьев в ансамбле\n",
    "n_trees = 20\n",
    "\n",
    "\n",
    "# Шаг\n",
    "eta =0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees, tagets_train, tagets_test = gb_fit(n_trees,train_data, test_data, train_labels, test_labels, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7859561716113276, 0.7899151486139392)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(train_labels, tagets_train), r2_score(test_labels, tagets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test.csv', index_col = 'Id')\n",
    "lessons = ['history','english', 'physics','chemistry','geography','biology']\n",
    "data_test = min_max(data_test)\n",
    "data_test.insert(3,'les',(sum([data_test[i]*data_0.corr()['mean_exam_points'][i] for i in lessons])))\n",
    "data_test.drop(columns =['age',*lessons], inplace = True)\n",
    "data_test_x=data_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees, tagets_train, tagets_test = gb_fit(n_trees,data_X, data_test_x, data_y, test_labels, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd_pred= pd.DataFrame({'Id':data_test.index, 'mean_exam_points': tagets_test}, )\n",
    "pd_pred.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
